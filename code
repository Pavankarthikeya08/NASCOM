
import os
import speech_recognition as sr
from pydub import AudioSegment
import requests

# ğŸ”¹ Hugging Face API Key (Replace with your own key)
HUGGINGFACE_API_KEY = "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"

# ğŸ”¹ Step 1: Convert Audio to Text
def audio_to_text(audio_path):
    recognizer = sr.Recognizer()

    # Convert MP3 to WAV if needed
    if audio_path.endswith(".mp3"):
        wav_path = audio_path.replace(".mp3", ".wav")
        AudioSegment.from_mp3(audio_path).export(wav_path, format="wav")
        audio_path = wav_path

    with sr.AudioFile(audio_path) as source:
        print("ğŸ™ï¸ Converting Audio to Text...")
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data)
            print(f"âœ… Recognized Text: {text}")
            return text
        except sr.UnknownValueError:
            print("âŒ Could not understand the audio.")
            return None
        except sr.RequestError:
            print("âŒ Could not request results, check your internet connection.")
            return None

# ğŸ”¹ Step 2: Generate an Art Description using Hugging Face's Text Generation API
def generate_art_description(text):
    print("ğŸ¤– Generating Art Description...")

    API_URL = "https://api-inference.huggingface.co/models/gpt2"  # GPT-2 for text generation
    headers = {"Authorization": f"Bearer {HUGGINGFACE_API_KEY}"}

    # Post request to Hugging Face API to generate text
    response = requests.post(API_URL, headers=headers, json={"inputs": f"Create a detailed art description based on: {text}"})

    if response.status_code == 200:
        generated_text = response.json()[0]["generated_text"]
        print(f"ğŸ“ AI-Generated Art Description: {generated_text}")
        return generated_text
    else:
        print(f"âŒ Failed to generate text. Error: {response.text}")
        return None

# ğŸ”¹ Step 3: Generate an Image using Hugging Face's Image Generation API (Stable Diffusion)
def generate_image(description):
    print("ğŸ¨ Generating Image from Description...")

    API_URL = "https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5"
    headers = {"Authorization": f"Bearer {HUGGINGFACE_API_KEY}"}

    response = requests.post(API_URL, headers=headers, json={"inputs": description})

    if response.status_code == 200:
        image_filename = "generated_image.png"
        with open(image_filename, "wb") as file:
            file.write(response.content)
        print(f"âœ… Image saved as {image_filename}")
    else:
        print(f"âŒ Failed to generate image. Error: {response.text}")

# ğŸ”¹ Step 4: Main Execution
def main():
    from google.colab import files
    uploaded = files.upload()
    audio_path = list(uploaded.keys())[0]  # Get uploaded filename

    recognized_text = audio_to_text(audio_path)

    if recognized_text:
        art_description = generate_art_description(recognized_text)
        if art_description:
            generate_image(art_description)

if __name__ == "__main__":
    main()
